{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "These days Smartphones have become an integral part of our life. We cannot assume our life without a mobile phone. Since, the advent of Smartphones, a revolution has been created in the mobile communication industry. Smartphones are not just restricted for calling these days. Infact, they are more often used for entertainment purpose.<br><br>\n",
    "Smartphone manufacturing companies load Smartphones with various sensors to enhance the user experinece. Two of the such sensors are <b>Accelerometer</b> and <b>Gyroscope</b>. <b>Accelerometer</b> measures acceleration while <b>Gyroscope</b> measures angular velocity.<br><br>\n",
    "Here, we will try to use the data provided by accelerometer and gyroscope of Smartphone to classify the activity which a Smartphone user is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this is Useful?\n",
    "These days, in addition to Smartphones, we are also using Smart-Watches like Fitbit or Apple-Watch, which help us to track our health. They monitor our each activity throughout the day check how many calories we have burnt. How many hours have we slept. However, in addition to Accelerometer and Gyroscope, they also use Heart-Rate data to monitor our activity. Since, we only have Smartphone data so just by using  Accelerometer and Gyroscope data we will monitor the activity of a person. This software can then be converted into an App which can be downloaded in Smartphone. Hence, a person who has Smartphone can monitor his/her health using this App\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about Data\n",
    "### How Data is recorded\n",
    " The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities <b>(WALKING, WALKING-UPSTAIRS, WALKING-DOWNSTAIRS, SITTING-DOWN, STANDING-UP, LAYING-DOWN)</b> wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n",
    "5.2. Features\n",
    "1. These sensor signals are pre-processed by applying noise filters and then sampled in fixed-width windows(sliding windows) of 2.56 seconds each with 50% overlap. i.e., each window has 128 readings. A 128 size vector is created from each window.\n",
    "2. From Each window or to be more precise, from each 128 readings domain experts from signal processing have engineered feature vector of size 561 by calculating variables from the time and frequency domain. In our dataset, each data-point represents a window with different readings.\n",
    "3. 561 features are stored in the file \"Features.docx\". Check it out. \n",
    "4. Check out 561 features here.(In your blog give here the link of the docx file of features which you upload on github).\n",
    "5. The acceleration signal was separated into Body and     Gravity acceleration signals(tBodyAcc-XYZ and tGravityAcc-XYZ) using some low pass filter with corner frequency of 0.3Hz.\n",
    "6. After that, the body linear acceleration and angular velocity were derived in time to obtain jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ).\n",
    "7. The magnitude of these 3-dimensional signals were calculated using the Euclidian norm. This magnitudes are represented as features with names like tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag and tBodyGyroJerkMag.\n",
    "8. Finally, We've got frequency domain signals from some of the available signals by applying a FFT (Fast Fourier Transform). These signals obtained were labelled with prefix 'f' just like original signals with prefix 't'. These signals are labelled as fBodyAcc-XYZ, fBodyGyroMag etc.<br>\n",
    "\n",
    "These are the signals that we got so far.\n",
    "\n",
    "* tBodyAcc-XYZ\n",
    "* tGravityAcc-XYZ\n",
    "* tBodyAccJerk-XYZ\n",
    "* tBodyGyro-XYZ\n",
    "* tBodyGyroJerk-XYZ\n",
    "* tBodyAccMag\n",
    "* tGravityAccMag\n",
    "* tBodyAccJerkMag\n",
    "* tBodyGyroMag\n",
    "* tBodyGyroJerkMag\n",
    "* fBodyAcc-XYZ\n",
    "* fBodyAccJerk-XYZ\n",
    "* fBodyGyro-XYZ\n",
    "* fBodyAccMag\n",
    "* fBodyAccJerkMag\n",
    "* fBodyGyroMag\n",
    "* fBodyGyroJerkMag<br><br>\n",
    "\n",
    "9 We can estimate some set of variables from the above signals. i.e., We will estimate the following properties on each and every signal that we recorded so far.\n",
    "* mean(): Mean value\n",
    "* std(): Standard deviation\n",
    "* mad(): Median absolute deviation\n",
    "* max(): Largest value in array\n",
    "* min(): Smallest value in array\n",
    "* sma(): Signal magnitude area\n",
    "* energy(): Energy measure. Sum of the squares divided by the number of values.\n",
    "* iqr(): Inter-quartile range\n",
    "* entropy(): Signal entropy\n",
    "* arCoeff(): Auto-regression coefficients with Burg order equal to 4\n",
    "* correlation(): correlation coefficient between two signals\n",
    "* maxInds(): index of the frequency component with largest magnitude\n",
    "* meanFreq(): Weighted average of the frequency components to obtain a mean frequency\n",
    "* skewness(): skewness of the frequency domain signal\n",
    "* kurtosis(): kurtosis of the frequency domain signal\n",
    "* bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.\n",
    "* angle(): Angle between to vectors.<br><br>\n",
    "\n",
    "10 We can obtain some other vectors by taking the average of signals in a single window sample. These are used on the angle() variable.\n",
    "* gravityMean\n",
    "* tBodyAccMean\n",
    "* tBodyAccJerkMean\n",
    "* tBodyGyroMean\n",
    "* tBodyGyroJerkMean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "Data is downloaded from following source:<br>\n",
    "https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Overview of Dataset\n",
    "Accelerometer and Gyroscope readings are taken from 30 volunteers(referred as subjects) while performing the following 6 Activities.<br><br>\n",
    "<b>These activites are encoded as follows:<br>\n",
    "WALKING-- 1<br>\n",
    "WALKING_UPSTAIRS-- 2<br>\n",
    "WALKING_DOWNSTAIRS-- 3<br>\n",
    "SITTING-- 4<br>\n",
    "STANDING-- 5<br>\n",
    "LYING-- 6<br>\n",
    "</b>\n",
    "* Readings are divided into a window of 2.56 seconds with 50% overlapping.\n",
    "* Accelerometer readings are divided into gravity acceleration and body acceleration readings, which has x, y and z components each.\n",
    "* Gyroscope readings are the measure of angular velocities which has x, y and z components.\n",
    "* Jerk signals are calculated for Body-Acceleration readings.\n",
    "* Fourier Transforms are made on the above time readings to obtain frequency readings.\n",
    "* Now, on all the base signal readings., mean, max, mad, sma, arcoefficient, energy-bands, entropy etc., are calculated for each window.\n",
    "* Extra features are calculated by taking the average of signals in a single window sample. These are used on the angle() variable.\n",
    "* Finally, we got feature vector of 561 features and these features are given in the dataset.\n",
    "* Each window of readings is a data-point of 561 features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y-Encoded Labels\n",
    "WALKING-- 1<br>\n",
    "WALKING_UPSTAIRS-- 2<br>\n",
    "WALKING_DOWNSTAIRS-- 3<br>\n",
    "SITTING-- 4<br>\n",
    "STANDING-- 5<br>\n",
    "LYING-- 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "Work-flow is as follows:<br>\n",
    "1. Domain experts from the field of Signal Processing collects the data from Accelerometer and Gyroscope of Smartphone.\n",
    "2. They break up the data in the time window of 2.56 seconds with 50% overlapping i.e., 128 reading\n",
    "3. They engineered 561 features from each time window of 2.56 seconds.<br>\n",
    "\n",
    "<b>By using either human engineered 561 feature data or raw features of 128 reading, our goal is to predict one of the six activities that a Smartphone user is performing at that 2.56 Seconds time window</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "<br> By using either human engineered 561 feature data or raw features of 128 reading, our goal is to predict one of the six activities that a Smartphone user is performing at that 2.56 Seconds time window.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective and Constraints\n",
    "1. No Low latency requirement.\n",
    "2. Errors are not much costly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Problem Formulation\n",
    "All of the Accelerometer and Gyroscope are tri-axial, means that they measure acceleration and angular-velocity respectively in all the three axis namely X-axis, Y-axis and Z-axis. So, we have in total six time-series data. Given this six time-series data, we want to predict six activities namely <b>Walking</b> or <b>Walking-Upstairs</b> or <b>Walking-Downstairs</b> or <b>Lying-Down</b> or <b>Standing-Up</b> or <b>Sitting-Down</b>.<br><br>\n",
    "<b>At the outset, this is a multi-class classification problem.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metric\n",
    "1. We will use Accuracy as one of the metric.\n",
    "2. We will also use Confusion-Matrix to check that in which two activities our model is confused and predicting incorrect activity. For example, between Standing-Up and Sitting-Down. Between Walking-Upstairs and Walking-Downstairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "All the data is present in 'UCI_HAR_dataset/' folder in present working directory.<br>\n",
    "Feature names are present in 'UCI_HAR_dataset/features.txt'<br><br>\n",
    "<b>Train Data</b><br>\n",
    "'UCI_HAR_dataset/train/X_train.txt'<br>\n",
    "'UCI_HAR_dataset/train/subject_train.txt'<br>\n",
    "'UCI_HAR_dataset/train/y_train.txt'<br>\n",
    "<b>Test Data</b><br>\n",
    "'UCI_HAR_dataset/test/X_test.txt'<br>\n",
    "'UCI_HAR_dataset/test/subject_test.txt'<br>\n",
    "'UCI_HAR_dataset/test/y_test.txt'<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Points Distribution\n",
    "* 30 test-subjects data is randomly split to 70%(21) train and 30%(7) test data.\n",
    "* Each data-point corresponds one of the 6 Activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of Action\n",
    "* We will apply classical Machine Learning models on these 561 sized domain expert engineered features. \n",
    "* As we know that LSTM works well on time-series data, so we have decided that we will apply LSTM of Recurrent Neural Networks on 128 sized raw readings that we obtained from accelerometer and gyroscope signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list()\n",
    "with open(\"UCI_HAR_dataset/features.txt\") as f:\n",
    "    for line in f:\n",
    "        features.append(line.split()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>activity_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X      ...        \\\n",
       "0         -0.923527         -0.934724      ...         \n",
       "1         -0.957686         -0.943068      ...         \n",
       "2         -0.977469         -0.938692      ...         \n",
       "3         -0.989302         -0.938692      ...         \n",
       "4         -0.990441         -0.942469      ...         \n",
       "\n",
       "   angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "0                    -0.112754                              0.030400   \n",
       "1                     0.053477                             -0.007435   \n",
       "2                    -0.118559                              0.177899   \n",
       "3                    -0.036788                             -0.012892   \n",
       "4                     0.123320                              0.122542   \n",
       "\n",
       "   angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "0                         -0.464761                             -0.018446   \n",
       "1                         -0.732626                              0.703511   \n",
       "2                          0.100699                              0.808529   \n",
       "3                          0.640011                             -0.485366   \n",
       "4                          0.693578                             -0.615971   \n",
       "\n",
       "   angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  \\\n",
       "0             -0.841247              0.179941             -0.058627   \n",
       "1             -0.844788              0.180289             -0.054317   \n",
       "2             -0.848933              0.180637             -0.049118   \n",
       "3             -0.848649              0.181935             -0.047663   \n",
       "4             -0.847865              0.185151             -0.043892   \n",
       "\n",
       "   subject_id  activity  activity_name  \n",
       "0           1         5       STANDING  \n",
       "1           1         5       STANDING  \n",
       "2           1         5       STANDING  \n",
       "3           1         5       STANDING  \n",
       "4           1         5       STANDING  \n",
       "\n",
       "[5 rows x 564 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"UCI_HAR_dataset/train/X_train.txt\", delim_whitespace = True, names = features)\n",
    "\n",
    "train_df[\"subject_id\"] = pd.read_csv(\"UCI_HAR_dataset/train/subject_train.txt\", header = None, squeeze = True) #squeeze = True will \n",
    "#return data in pandas series format\n",
    "\n",
    "train_df[\"activity\"] = pd.read_csv(\"UCI_HAR_dataset/train/y_train.txt\", header = None, squeeze = True)\n",
    "\n",
    "activity = pd.read_csv(\"UCI_HAR_dataset/train/y_train.txt\", header = None, squeeze = True)\n",
    "\n",
    "#mapping activity to activity name\n",
    "label_name = activity.map({1: \"WALKING\", 2:\"WALKING_UPSTAIRS\", 3:\"WALKING_DOWNSTAIRS\", 4:\"SITTING\", 5:\"STANDING\", 6:\"LYING\"})\n",
    "\n",
    "train_df[\"activity_name\"] = label_name\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Train data = (7352, 564)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Train data = {}\".format(train_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>activity_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.162920</td>\n",
       "      <td>-0.825886</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>-0.720009</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>-0.057978</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083495</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-0.434375</td>\n",
       "      <td>0.920593</td>\n",
       "      <td>-0.698091</td>\n",
       "      <td>0.281343</td>\n",
       "      <td>-0.083898</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>0.202302</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.145068</td>\n",
       "      <td>-0.702771</td>\n",
       "      <td>0.280083</td>\n",
       "      <td>-0.079346</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270298</td>\n",
       "      <td>-0.032614</td>\n",
       "      <td>-0.117520</td>\n",
       "      <td>-0.994743</td>\n",
       "      <td>-0.973268</td>\n",
       "      <td>-0.967091</td>\n",
       "      <td>-0.995274</td>\n",
       "      <td>-0.974471</td>\n",
       "      <td>-0.968897</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017067</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.340134</td>\n",
       "      <td>0.296407</td>\n",
       "      <td>-0.698954</td>\n",
       "      <td>0.284114</td>\n",
       "      <td>-0.077108</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274833</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>-0.129527</td>\n",
       "      <td>-0.993852</td>\n",
       "      <td>-0.967445</td>\n",
       "      <td>-0.978295</td>\n",
       "      <td>-0.994111</td>\n",
       "      <td>-0.965953</td>\n",
       "      <td>-0.977346</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>-0.040046</td>\n",
       "      <td>0.736715</td>\n",
       "      <td>-0.118545</td>\n",
       "      <td>-0.692245</td>\n",
       "      <td>0.290722</td>\n",
       "      <td>-0.073857</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.257178          -0.023285          -0.014654         -0.938404   \n",
       "1           0.286027          -0.013163          -0.119083         -0.975415   \n",
       "2           0.275485          -0.026050          -0.118152         -0.993819   \n",
       "3           0.270298          -0.032614          -0.117520         -0.994743   \n",
       "4           0.274833          -0.027848          -0.129527         -0.993852   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.920091         -0.667683         -0.952501         -0.925249   \n",
       "1         -0.967458         -0.944958         -0.986799         -0.968401   \n",
       "2         -0.969926         -0.962748         -0.994403         -0.970735   \n",
       "3         -0.973268         -0.967091         -0.995274         -0.974471   \n",
       "4         -0.967445         -0.978295         -0.994111         -0.965953   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X      ...        \\\n",
       "0         -0.674302         -0.894088      ...         \n",
       "1         -0.945823         -0.894088      ...         \n",
       "2         -0.963483         -0.939260      ...         \n",
       "3         -0.968897         -0.938610      ...         \n",
       "4         -0.977346         -0.938610      ...         \n",
       "\n",
       "   angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "0                     0.006462                              0.162920   \n",
       "1                    -0.083495                              0.017500   \n",
       "2                    -0.034956                              0.202302   \n",
       "3                    -0.017067                              0.154438   \n",
       "4                    -0.002223                             -0.040046   \n",
       "\n",
       "   angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "0                         -0.825886                              0.271151   \n",
       "1                         -0.434375                              0.920593   \n",
       "2                          0.064103                              0.145068   \n",
       "3                          0.340134                              0.296407   \n",
       "4                          0.736715                             -0.118545   \n",
       "\n",
       "   angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  \\\n",
       "0             -0.720009              0.276801             -0.057978   \n",
       "1             -0.698091              0.281343             -0.083898   \n",
       "2             -0.702771              0.280083             -0.079346   \n",
       "3             -0.698954              0.284114             -0.077108   \n",
       "4             -0.692245              0.290722             -0.073857   \n",
       "\n",
       "   subject_id  activity  activity_name  \n",
       "0           2         5       STANDING  \n",
       "1           2         5       STANDING  \n",
       "2           2         5       STANDING  \n",
       "3           2         5       STANDING  \n",
       "4           2         5       STANDING  \n",
       "\n",
       "[5 rows x 564 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"UCI_HAR_dataset/test/X_test.txt\", delim_whitespace = True, names = features)\n",
    "\n",
    "test_df[\"subject_id\"] = pd.read_csv(\"UCI_HAR_dataset/test/subject_test.txt\", header = None, squeeze = True) #squeeze = True will \n",
    "#return data in pandas series format\n",
    "\n",
    "test_df[\"activity\"] = pd.read_csv(\"UCI_HAR_dataset/test/y_test.txt\", header = None, squeeze = True)\n",
    "\n",
    "activity = pd.read_csv(\"UCI_HAR_dataset/test/y_test.txt\", header = None, squeeze = True)\n",
    "\n",
    "#mapping activity to activity name\n",
    "label_name = activity.map({1: \"WALKING\", 2:\"WALKING_UPSTAIRS\", 3:\"WALKING_DOWNSTAIRS\", 4:\"SITTING\", 5:\"STANDING\", 6:\"LYING\"})\n",
    "\n",
    "test_df[\"activity_name\"] = label_name\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Test data = (2947, 564)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Test data = {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in train data is 0\n",
      "Number of NaN values in test data is 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for nan values\n",
    "print(\"Number of NaN values in train data is \"+str(train_df.isnull().sum().sum()))\n",
    "print(\"Number of NaN values in test data is \"+str(test_df.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate values in train data is 0\n",
      "Number of duplicate values in test data is 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate values\n",
    "print(\"Number of duplicate values in train data is \"+str(sum(train_df.duplicated())))\n",
    "print(\"Number of duplicate values in test data is \"+str(sum(test_df.duplicated())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Checking for imbalance in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'isna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-22b22f95eb23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Activity by each test subject\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"subject_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"activity_name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Subject ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Count\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mcountplot\u001b[1;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, dodge, ax, **kwargs)\u001b[0m\n\u001b[0;32m   3587\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3588\u001b[0m         \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3589\u001b[1;33m         \u001b[0merrcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdodge\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3590\u001b[0m     )\n\u001b[0;32m   3591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[0;32m   1583\u001b[0m         \u001b[1;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         self.establish_variables(x, y, hue, data, orient,\n\u001b[1;32m-> 1585\u001b[1;33m                                  order, hue_order, units)\n\u001b[0m\u001b[0;32m   1586\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1587\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_statistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;31m# Figure out the plotting orientation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             orient = infer_orient(\n\u001b[1;32m--> 157\u001b[1;33m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m             )\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36minfer_orient\u001b[1;34m(x, y, orient, require_numeric)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \"\"\"\n\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m     \u001b[0mx_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvariable_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvariable_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36mvariable_type\u001b[1;34m(vector, boolean_type)\u001b[0m\n\u001b[0;32m   1201\u001b[0m     \"\"\"\n\u001b[0;32m   1202\u001b[0m     \u001b[1;31m# Special-case all-na data, which is always \"numeric\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"numeric\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'isna'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title(\"Activity by each test subject\", fontsize = 15)\n",
    "plt.tick_params(labelsize = 15)\n",
    "sns.countplot(x = \"subject_id\", hue = \"activity_name\", data = train_df)\n",
    "plt.xlabel(\"Subject ID\", fontsize = 15)\n",
    "plt.ylabel(\"Count\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title(\"Count of each activity\", fontsize = 15)\n",
    "plt.tick_params(labelsize = 10)\n",
    "sns.countplot(x = \"activity_name\", data = train_df)\n",
    "for i in ax.patches:\n",
    "    ax.text(x = i.get_x() + 0.2, y = i.get_height()+10, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\", fontsize = 15)\n",
    "plt.tick_params(labelsize = 13)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b><br>\n",
    "From the above two plots, we can infer that our classes are almost balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Changing Feature Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = columns.str.replace(\"[()]\", '') \n",
    "columns = columns.str.replace(\"-\", '')\n",
    "columns = columns.str.replace(\",\", '')\n",
    "#here, columns is of type pandas index. By writing \"columns.str\" we have changed its type to \n",
    "#pandas string. Pandas string has method called replace which we have used here.\n",
    "\n",
    "train_df.columns = columns\n",
    "test_df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving Dataframe for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"../Data/train/train_df.csv\", index = False)\n",
    "test_df.to_csv(\"../Data/test/test_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Data/train/train_df.csv\")\n",
    "test_df = pd.read_csv(\"../Data/test/test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature information from domain knowledge</b>\n",
    "1. <b>Static:</b> We have three types static features where test subject is in rest:\n",
    "    * Sitting\n",
    "    * Standing\n",
    "    * Lying\n",
    "2. <b>Dynamic:</b> We have three types of dynamic features where test subject is in motion:\n",
    "    * Walking\n",
    "    * Walking_Downstairs\n",
    "    * Walking_Upstairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude of Body Accelerator Mean Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facetgrid = sns.FacetGrid(data = train_df, hue = \"activity_name\", size = 8)\n",
    "facetgrid.map(sns.distplot, \"tBodyAccMagmean\", hist = False).add_legend()\n",
    "plt.annotate('Static Activities(Sitting, Standing, Lying)', xy=(-0.97, 23), xytext=(-0.7, 27),\n",
    "            arrowprops=dict(facecolor='orange', width = 7, headlength = 15), size = 15, color = \"#232b2b\")\n",
    "plt.annotate('Dynamic Activities(Walking, Walking_Upstairs, Walking_Downstairs)', xy=(0.1, 3), xytext=(0.4, 6),\n",
    "            arrowprops=dict(facecolor='orange', width = 7, headlength = 13), size = 15, color = \"#232b2b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot \"tBodyAccMagmean\" for both static and dynamic activites separately to analysis them in more detail\n",
    "df_standing = train_df[train_df[\"activity_name\"] == \"STANDING\"]\n",
    "df_sitting = train_df[train_df[\"activity_name\"] == \"SITTING\"]\n",
    "df_lying = train_df[train_df[\"activity_name\"] == \"LYING\"]\n",
    "df_walking = train_df[train_df[\"activity_name\"] == \"WALKING\"]\n",
    "df_walking_upstairs = train_df[train_df[\"activity_name\"] == \"WALKING_UPSTAIRS\"]\n",
    "df_walking_downstairs = train_df[train_df[\"activity_name\"] == \"WALKING_DOWNSTAIRS\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 7))\n",
    "\n",
    "axes[0].set_title(\"Static Activities for tBodyAccMagmean--Zoomed In\")\n",
    "sns.distplot(df_standing[\"tBodyAccMagmean\"], hist = False, label = \"STANDING\", ax = axes[0])\n",
    "sns.distplot(df_sitting[\"tBodyAccMagmean\"], hist = False, label = \"SITTING\", ax = axes[0])\n",
    "sns.distplot(df_lying[\"tBodyAccMagmean\"], hist = False, label = \"Lying\", ax = axes[0])\n",
    "axes[0].legend(fontsize = 15)\n",
    "axes[0].annotate('Static Activities', xy=(-0.90, 15), xytext=(-0.7, 27),\n",
    "            arrowprops=dict(facecolor='orange', width = 7, headlength = 15), size = 15, color = \"#232b2b\")\n",
    "\n",
    "axes[1].set_title(\"Dynamic Activities for tBodyAccMagmean--Zoomed In\")\n",
    "sns.distplot(df_walking[\"tBodyAccMagmean\"], hist = False, label = \"WALKING\", ax = axes[1])\n",
    "sns.distplot(df_walking_upstairs[\"tBodyAccMagmean\"], hist = False, label = \"WALKING_UPSTAIRS\", ax = axes[1])\n",
    "sns.distplot(df_walking_downstairs[\"tBodyAccMagmean\"], hist = False, label = \"WALKING_DOWNSTAIRS\", ax = axes[1])\n",
    "axes[1].legend(fontsize = 15)\n",
    "axes[1].annotate('Dynamic Activities', xy=(0.37, 1.5), xytext=(0.60, 2.2),\n",
    "            arrowprops=dict(facecolor='orange', width = 7, headlength = 13), size = 15, color = \"#232b2b\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b><br>\n",
    "From above two plots we can clearly observe that how well \"tBodyAccMagmean\"--which is the magnitude of the mean of body acceleration in time-domain meaured by accelerometer--is able to separate static activity from dynamic activity. This shows that features are very carefully engineered by domian experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "sns.boxplot(x = \"activity_name\", y = \"tBodyAccMagmean\", showfliers = False, data = train_df)\n",
    "plt.axhline(y = -0.65, linestyle = \"--\")\n",
    "plt.axhline(y = 0, linestyle = \"--\")\n",
    "plt.title(\"Box plot of tBodyAccMagmean\", fontsize = 15)\n",
    "plt.ylabel(\"Accelerator Body Mean\", fontsize = 15)\n",
    "plt.xlabel(\"Activity Name\", fontsize = 15)\n",
    "plt.xlabel(\"\")\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observations:</b><br>\n",
    "* If tAccMean is < -0.8 then the Activities are either Standing or Sitting or Laying.\n",
    "* If tAccMean is > -0.6 then the Activities are either Walking or WalkingDownstairs or WalkingUpstairs.\n",
    "* If tAccMean > 0.0 then the Activity is WalkingDownstairs.\n",
    "* We can classify 75% the Acitivity labels with some errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerator Gravity Mean on X-axis can be quite important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "sns.boxplot(x = \"activity_name\", y = \"angleXgravityMean\", showfliers = True, data = train_df)\n",
    "plt.axhline(y = 0, linestyle = \"--\")\n",
    "plt.title(\"Box plot of tBodyAccMagmean\", fontsize = 15)\n",
    "plt.ylabel(\"Accelerator Gravity Mean on X-axis\", fontsize = 15)\n",
    "plt.xlabel(\"\")\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b><br>\n",
    "* If Acc Gravity Mean > 0, we can infer that the activity will most likely be <b>Lying</b>.\n",
    "* If Acc Gravity Mean < 0, we can infer that the activity can be anything but <b>Lying</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Applying T-SNE on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_tsne(perplexity, train_df):\n",
    "    data = train_df.drop([\"subject_id\", \"activity\", \"activity_name\"], axis = 1)\n",
    "    data_label = train_df[\"activity_name\"]\n",
    "    applying_tsne = TSNE(n_components = 2, perplexity = perplexity, n_iter = 1000, verbose = 2)\n",
    "    reduced_dim = applying_tsne.fit_transform(data)\n",
    "    d = {'Dimension_1': applying_tsne.embedding_[:,0], 'Dimension_2': applying_tsne.embedding_[:,1], \"activities\":data_label}\n",
    "    df = pd.DataFrame(data = d)\n",
    "    print(\"Done...\")\n",
    "    print(\"Plotting TSNE Visualization...\")\n",
    "    sns.set_style('whitegrid') \n",
    "    sns.lmplot(\"Dimension_1\", \"Dimension_2\", df, hue = 'activities', markers=['|','o','_', \">\", \"<\", \"^\"], fit_reg = False, size = 10, scatter_kws={'s':100})\n",
    "    plt.title(\"TSNE Plot for Perplexity \"+str(perplexity))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perplexities = [5, 10, 20, 40, 100]\n",
    "for perplexity in perplexities:\n",
    "    plt_tsne(perplexity, train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b><br>\n",
    "From above TSNE plots, we can observe that except <b>STANDING</b> and <b>SITTING</b>, all other activities are separated fairly well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop([\"subject_id\", \"activity\", \"activity_name\"], axis = 1)\n",
    "y_train = train_df[\"activity\"]\n",
    "\n",
    "x_test = test_df.drop([\"subject_id\", \"activity\", \"activity_name\"], axis = 1)\n",
    "y_test = test_df[\"activity\"]\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(columns = [\"Model\", \"Accuracy(%)\"])\n",
    "def keeping_record(model_name, accuracy):\n",
    "    global table\n",
    "    table = table.append(pd.DataFrame([[model_name, accuracy]], columns = [\"Model\", \"Accuracy(%)\"]))\n",
    "    table.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusionMatrix(Y_TestLabels, PredictedLabels):\n",
    "    confusionMatx = confusion_matrix(Y_TestLabels, PredictedLabels)\n",
    "    \n",
    "    precision = confusionMatx/confusionMatx.sum(axis = 0)\n",
    "    \n",
    "    recall = (confusionMatx.T/confusionMatx.sum(axis = 1)).T\n",
    "    \n",
    "    sns.set(font_scale=1.5)\n",
    "    \n",
    "    # confusionMatx = [[1, 2],\n",
    "    #                  [3, 4]]\n",
    "    # confusionMatx.T = [[1, 3],\n",
    "    #                   [2, 4]]\n",
    "    # confusionMatx.sum(axis = 1)  axis=0 corresponds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # confusionMatx.sum(axix =1) = [[3, 7]]\n",
    "    # (confusionMatx.T)/(confusionMatx.sum(axis=1)) = [[1/3, 3/7]\n",
    "    #                                                  [2/3, 4/7]]\n",
    "\n",
    "    # (confusionMatx.T)/(confusionMatx.sum(axis=1)).T = [[1/3, 2/3]\n",
    "    #                                                    [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    labels = [\"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\", \"SITTING\", \"STANDING\", \"LYING\"]\n",
    "    \n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.heatmap(confusionMatx, cmap = \"Blues\", annot = True, fmt = \".1f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Confusion Matrix\", fontsize = 30)\n",
    "    plt.xlabel('Predicted Class', fontsize = 20)\n",
    "    plt.ylabel('Original Class', fontsize = 20)\n",
    "    plt.tick_params(labelsize = 15)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*125)\n",
    "    \n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.heatmap(precision, cmap = \"Blues\", annot = True, fmt = \".2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Precision Matrix\", fontsize = 30)\n",
    "    plt.xlabel('Predicted Class', fontsize = 20)\n",
    "    plt.ylabel('Original Class', fontsize = 20)\n",
    "    plt.tick_params(labelsize = 15)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*125)\n",
    "    \n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.heatmap(recall, cmap = \"Blues\", annot = True, fmt = \".2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Recall Matrix\", fontsize = 30)\n",
    "    plt.xlabel('Predicted Class', fontsize = 20)\n",
    "    plt.ylabel('Original Class', fontsize = 20)\n",
    "    plt.tick_params(labelsize = 15)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(cross_val, x_train, y_train, x_test, y_test, model_name):\n",
    "    start = datetime.now()\n",
    "    cross_val.fit(x_train, y_train)\n",
    "    predicted_points = cross_val.predict(x_test)\n",
    "    \n",
    "    print(\"Total time taken for tuning hyperparameter and making prediction by the model is (HH:MM:SS): {}\\n\".format(datetime.now() - start))\n",
    "    accuracy = np.round(accuracy_score(y_test, predicted_points)*100, 2)\n",
    "    \n",
    "    print('---------------------')\n",
    "    print('|      Accuracy      |')\n",
    "    print('---------------------')\n",
    "    print(str(accuracy)+\"%\\n\")\n",
    "    \n",
    "    print('---------------------------')\n",
    "    print('|      Best Estimator      |')\n",
    "    print('---------------------------')\n",
    "    print(\"{}\\n\".format(cross_val.best_estimator_))\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    print('|      Best Hyper-Parameters      |')\n",
    "    print('----------------------------------')\n",
    "    print(cross_val.best_params_)\n",
    "    \n",
    "    keeping_record(model_name, accuracy)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    print_confusionMatrix(y_test, predicted_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {\"C\": [0.001, 0.01, 0.1, 1, 10**1, 10**2, 10**3], \"penalty\": [\"l1\", \"l2\"]}\n",
    "clf = LogisticRegression(multi_class = \"ovr\")\n",
    "cross_val = GridSearchCV(clf, parameters, cv=3)\n",
    "apply_model(cross_val, x_train, y_train, x_test, y_test, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {\"C\": [0.001, 0.01, 0.1, 1, 10**1, 10**2, 10**3]}\n",
    "clf = LinearSVC()\n",
    "cross_val = GridSearchCV(clf, parameters, cv=3)\n",
    "apply_model(cross_val, x_train, y_train, x_test, y_test, \"Linear SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {\"C\": [0.001, 0.01, 0.1, 1, 10**1, 10**2, 10**3]}\n",
    "clf = SVC()\n",
    "cross_val = GridSearchCV(clf, parameters, cv=3)\n",
    "apply_model(cross_val, x_train, y_train, x_test, y_test, \"RBF SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\": [2, 3, 4, 5, 6, 7, 8]}\n",
    "clf = DecisionTreeClassifier()\n",
    "cross_val = GridSearchCV(clf, parameters, cv=3)\n",
    "apply_model(cross_val, x_train, y_train, x_test, y_test, \"Decision Trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {\"n_estimators\": [50, 100, 200, 400, 800]}\n",
    "clf = RandomForestClassifier()\n",
    "cross_val = GridSearchCV(clf, parameters, cv=3)\n",
    "apply_model(cross_val, x_train, y_train, x_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {\"n_estimators\": [50, 100], \"max_depth\":[1, 3]}\n",
    "clf = GradientBoostingClassifier()\n",
    "cross_val = GridSearchCV(clf, parameters, cv=3)\n",
    "apply_model(cross_val, x_train, y_train, x_test, y_test, \"Gradient Boosted DT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = table.plot(x = \"Model\", y = \"Accuracy(%)\", kind = \"bar\", figsize = (14, 7), legend = False)\n",
    "plt.title(\"Models Accuracy Score\", fontsize = 20)\n",
    "plt.xlabel(\"\")\n",
    "plt.margins(x = 0, y = 0.08)\n",
    "plt.ylabel(\"Accuracy Score(%)\", fontsize = 20)\n",
    "plt.grid(visible = True)\n",
    "for i in ax.patches:\n",
    "    ax.text(x = i.get_x()+0.05, y = i.get_height()+1, s = str(i.get_height())+\"%\", fontsize = 16, color = \"#232b2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comments</b><br>\n",
    "* Models: Logistic Regression, rbf SVM and Linear SVM give accuracy above 96%.\n",
    "* In real world, having domain knowledge is one of the most important aspects of machine learning Modelling. Here, we got pretty good accuracy of above 96%. This is very much due to the fact that features are very well engineered by domain experts in signal processing.<br>\n",
    "* In a nutshell, feature engineering is one of the most important aspect of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Applying Deep Learning Model: LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Here in LSTM, we will use 128 sized raw readings that we obtained from accelerometer and gyroscope signals.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals_list = [\"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\", \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\", \n",
    "                   \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_data(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace = True, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_signal_matrix(trainOrTest):\n",
    "    complete_data = []\n",
    "    for signal in all_signals_list:\n",
    "        complete_data.append(reading_data(\"../Data/\"+ trainOrTest +\"/Inertial Signals/\"+ signal + trainOrTest +\".txt\").as_matrix())\n",
    "    return np.transpose(complete_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(subset):\n",
    "    filename = \"../Data/\"+subset+\"/y_\"+subset+\".txt\"\n",
    "    y = reading_data(filename)\n",
    "    return pd.get_dummies(y[0]).as_matrix()\n",
    "# here, get_dummies takes pandas series as input and returns its one-hot encoded vector of each element in a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_data():\n",
    "    x_train = total_signal_matrix(\"train\")\n",
    "    y_train = load_labels(\"train\")\n",
    "    x_test = total_signal_matrix(\"test\")\n",
    "    y_test = load_labels(\"test\")\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_full_data()\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data for loading it later in hyperas for hyper-parameter tuning\n",
    "np.save(\"../Data/train\", x_train)\n",
    "np.save(\"../Data/train_label\", y_train)\n",
    "np.save(\"../Data/test\", x_test)\n",
    "np.save(\"../Data/test_label\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    x_train = np.load(\"../Data/train.npy\")\n",
    "    y_train = np.load(\"../Data/train_label.npy\")\n",
    "    x_test = np.load(\"../Data/test.npy\")\n",
    "    y_test = np.load(\"../Data/test_label.npy\")\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will return number of classes\n",
    "def count_unique_classes(y_train):\n",
    "    return len(set([tuple(a) for a in y_train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Hyper-Parameter Tuning with Hyperas and Applying LSTM with best Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer documentation of hyperas here: https://github.com/maxpumperla/hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    epochs = 8\n",
    "    batch_size = 32\n",
    "    timesteps = x_train.shape[1]\n",
    "    input_dim = len(x_train[0][0])\n",
    "    n_classes = 6\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(64, return_sequences = True, input_shape = (timesteps, input_dim)))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(LSTM({{choice([32, 16])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense(n_classes, activation='sigmoid'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
    "    \n",
    "    result = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, verbose=2, validation_split=0.01)\n",
    "    \n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    \n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model, data=data, algo=tpe.suggest, max_evals=4, trials=Trials(), notebook_name = \"HumanActivityRecognition\")\n",
    "x_train, y_train, x_test, y_test = data()\n",
    "\n",
    "score = best_model.evaluate(x_test, y_test)\n",
    "\n",
    "print('---------------------')\n",
    "print('|      Accuracy      |')\n",
    "print('---------------------')\n",
    "acc = np.round((score[1]*100), 2)\n",
    "print(str(acc)+\"%\\n\")\n",
    "    \n",
    "print('----------------------------------')\n",
    "print('|      Best Hyper-Parameters      |')\n",
    "print('----------------------------------')\n",
    "print(best_run)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "true_labels = [np.argmax(i)+1 for i in y_test]\n",
    "predicted_probs = best_model.predict(x_test)\n",
    "predicted_labels = [np.argmax(i)+1 for i in predicted_probs]\n",
    "print_confusionMatrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Final Comments</b>\n",
    "* By Simple two layered LSTM, we got a good accuracy of 87.72%. In short, DeeP Learning help us to built models even when we don't have domain expert engineered features. \n",
    "* LSTM model can be further improved by running it for more epochs and more evaluations while tuning hyper-parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
